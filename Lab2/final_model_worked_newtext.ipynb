{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "7Ehnnm71Ec0A"
      },
      "outputs": [],
      "source": [
        "#pip install tensorflow==2.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5xqDKxMrLZ2",
        "outputId": "465e2ad8-a22f-44b4-e1fb-25d41f3c0898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.7/dist-packages (2.11.0)\n",
            "Requirement already satisfied: tensorflow<2.12,>=2.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.11.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.27.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (14.0.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (21.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.19.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (4.1.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (22.11.23)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.11.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.50.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.11.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.11.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.38.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.14.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tensorflow_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "H_B9ls8QsSUY"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as thub\n",
        "import tensorflow_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "nqv89586sSUa"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "import PIL\n",
        "from PIL import ImageOps\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32gm8rrDsSUb"
      },
      "source": [
        "# Get data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x3sKLYRsSUc"
      },
      "source": [
        "### imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzvYaoCK7gxS",
        "outputId": "f6b9abbc-5688-4d12-ed66-daa51fb1a522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/drive/MyDrive/IMDB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "JkE8LEHzjRWq",
        "outputId": "affb0123-3d81-40a7-d577-86d36363851f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-5c6f6bcb3ef2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontent\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdrive\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mMyDrive\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mIMDB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'content' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYWS_fCDsSUd"
      },
      "outputs": [],
      "source": [
        "PATH = '/content/drive/MyDrive/lab_2/IMDB_new/final_storage/train'\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (160, 160)\n",
        "seed = 42\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJoi3qXTUbdM"
      },
      "outputs": [],
      "source": [
        "train_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDNShJgLsSUd"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory('/content/drive/MyDrive/IMDB/final_storage/train',\n",
        "                                                            shuffle=True,\n",
        "                                                            batch_size=BATCH_SIZE,\n",
        "                                                            image_size=IMG_SIZE,\n",
        "                                                            validation_split = 0.2,\n",
        "                                                            subset = 'training',\n",
        "                                                            seed = 42)\n",
        "\n",
        "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory('/content/drive/MyDrive/IMDB/final_storage/train',\n",
        "                                                                 shuffle=True,\n",
        "                                                                 batch_size=BATCH_SIZE,\n",
        "                                                                 image_size=IMG_SIZE,\n",
        "                                                                 validation_split = 0.2,\n",
        "                                                                 subset = 'validation',\n",
        "                                                                 seed = 42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9Pwa4jHsSUe"
      },
      "outputs": [],
      "source": [
        "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/IMDB/old_storage_text/train',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=seed)\n",
        "\n",
        "# class_names = raw_train_ds.class_names\n",
        "# train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/IMDB/old_storage_text/train',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXlH4-GtsSUf"
      },
      "source": [
        "#### check sets that coincide "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNCv9zG1sSUg"
      },
      "source": [
        "# Model setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K55CVAbwsSUh"
      },
      "outputs": [],
      "source": [
        "\n",
        "class_names = train_dataset.class_names\n",
        "classes_num  = len(class_names)\n",
        "print(class_names)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_dataset.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN3CNHX-sSUh"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZotmPUgxsSUh"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "   tf.keras.layers.RandomFlip('horizontal'),\n",
        "   tf.keras.layers.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "\n",
        "for image, _ in train_dataset.take(1):\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  first_image = image[0]\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
        "    plt.imshow(augmented_image[0] / 255)\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJMTDyQCsSUh"
      },
      "outputs": [],
      "source": [
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "#IMG_SHAPE = IMG_SIZE \n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "image_batch, label_batch = next(iter(train_dataset))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(label_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN_0NX25sSUj"
      },
      "source": [
        "## Model itself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iam4q583sSUk"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = True\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "prediction_layer = tf.keras.layers.Dense(classes_num)\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql2HzF5bsSUl"
      },
      "source": [
        "### Prepare data for multi-inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjgrplTosSUl"
      },
      "outputs": [],
      "source": [
        "\n",
        "img_features = []\n",
        "for img_batch, img_label_batch in train_dataset:\n",
        "    for singe in img_batch:\n",
        "        img_features.append(singe)\n",
        "text_features = []\n",
        "text_labels = []\n",
        "for text_batch, label_batch in train_ds:\n",
        "    for single in text_batch:\n",
        "        text_features.append(single)\n",
        "    for single in label_batch:\n",
        "        text_labels.append(single)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdfytJIosSUl"
      },
      "outputs": [],
      "source": [
        "text_features_st = tf.stack(text_features)\n",
        "img_features_st = tf.stack(img_features)\n",
        "labels_st = tf.stack(text_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GpeHdU0sSUl"
      },
      "outputs": [],
      "source": [
        "a = tf.data.Dataset.from_tensor_slices(img_features_st)\n",
        "b = tf.data.Dataset.from_tensor_slices(text_features_st)\n",
        "c = tf.data.Dataset.from_tensor_slices(labels_st)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaHax7RqsSUl"
      },
      "outputs": [],
      "source": [
        "a = a.batch(32)\n",
        "b = b.batch(32)\n",
        "c = c.batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shMAnZhHsSUm"
      },
      "outputs": [],
      "source": [
        "combined_dataset = tf.data.Dataset.zip(((a,b),c))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8mxk6EjsSUm"
      },
      "outputs": [],
      "source": [
        "initial_epochs = 15\n",
        "\n",
        "history = model.fit(combined_dataset , epochs=initial_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSIza23icBna"
      },
      "outputs": [],
      "source": [
        "img_features = []\n",
        "for img_batch, img_label_batch in validation_dataset:\n",
        "    for singe in img_batch:\n",
        "        img_features.append(singe)\n",
        "text_features = []\n",
        "text_labels = []\n",
        "for text_batch, label_batch in val_ds:\n",
        "    for single in text_batch:\n",
        "        text_features.append(single)\n",
        "    for single in label_batch:\n",
        "        text_labels.append(single)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfedzT_SqK20"
      },
      "outputs": [],
      "source": [
        "val_text_features_st = tf.stack(text_features)\n",
        "val_img_features_st = tf.stack(img_features)\n",
        "val_labels_st = tf.stack(text_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHFeVutZedIx"
      },
      "outputs": [],
      "source": [
        "val_a = tf.data.Dataset.from_tensor_slices(val_img_features_st)\n",
        "val_b = tf.data.Dataset.from_tensor_slices(val_text_features_st)\n",
        "val_c = tf.data.Dataset.from_tensor_slices(val_labels_st)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeALzentepav"
      },
      "outputs": [],
      "source": [
        "val_a = val_a.batch(32)\n",
        "val_b = val_b.batch(32)\n",
        "val_c = val_c.batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKuDbfIseuOm"
      },
      "outputs": [],
      "source": [
        "validation_combined_dataset = tf.data.Dataset.zip(((val_a,val_b),val_c))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9qy8Q9Ee5PB"
      },
      "source": [
        "### Try with validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57fRE6--e8CP"
      },
      "outputs": [],
      "source": [
        "initial_epochs = 15\n",
        "history = model.fit(combined_dataset , epochs=initial_epochs, validation_data=validation_combined_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syJNWhkUHgRX"
      },
      "source": [
        "### something new and probably special"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Umrz6FnGASE"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = True\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "prediction_layer = tf.keras.layers.Dense(classes_num)\n",
        "prediction_batch = prediction_layer(feature_batch_average)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3A6OqQoSGICg"
      },
      "outputs": [],
      "source": [
        "try: \n",
        "    del model\n",
        "except:\n",
        "    2+2\n",
        "\n",
        "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs_img = tf.keras.layers.Dense(100)(x)\n",
        "#outputs_img = prediction_layer(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5Le6n98GIAJ"
      },
      "outputs": [],
      "source": [
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "# text_input = tf.keras.layers.Input(shape=(),)\n",
        "\n",
        "# text_input = layers.Embedding(input_dim=max_features+1, output_dim=embedding_dim, input_length=sequence_length, name='vectorized_text')\n",
        "\n",
        "preprocessing_layer = thub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "encoder_inputs = preprocessing_layer(text_input)\n",
        "\n",
        "encoder = thub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "outputs = encoder(encoder_inputs)\n",
        "\n",
        "net = outputs['pooled_output']\n",
        "net = tf.keras.layers.Dense(24, name='classifier')(net)\n",
        "net = tf.keras.layers.Dropout(0.5)(net)\n",
        "model_merging = concatenate([outputs_img,net]) \n",
        "\n",
        "final = tf.keras.layers.Dense(classes_num, activation='sigmoid', name='finalmente')(model_merging)\n",
        "\n",
        "\n",
        "model = tf.keras.Model([inputs,text_input], final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vui3eca6GH9x"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_lAc9ikGHod"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.losses as losses\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "# model.compile(\n",
        "model.compile(\n",
        "    # loss=losses.BinaryCrossentropy(from_logits=True),\n",
        "    loss=losses.CategoricalCrossentropy(),\n",
        "    #optimizer='adam',\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10), \n",
        "    # metrics=tf.metrics.BinaryAccuracy(threshold=0.0)\n",
        "    #metrics=tf.metrics.CategoricalAccuracy()\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeBBI-92G2zn"
      },
      "outputs": [],
      "source": [
        "\n",
        "img_features = []\n",
        "for img_batch, img_label_batch in train_dataset:\n",
        "    for singe in img_batch:\n",
        "        img_features.append(singe)\n",
        "text_features = []\n",
        "text_labels = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-86EF80G2xR"
      },
      "outputs": [],
      "source": [
        "img_features_st = tf.stack(img_features)\n",
        "#labels_st = tf.stack(text_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hKpUSegG2uo"
      },
      "outputs": [],
      "source": [
        "a = tf.data.Dataset.from_tensor_slices(img_features_st)\n",
        "#b = tf.data.Dataset.from_tensor_slices(text_features_st)\n",
        "#c = tf.data.Dataset.from_tensor_slices(labels_st)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6SdxtEbG2hb"
      },
      "outputs": [],
      "source": [
        "a = a.batch(32)\n",
        "b = b.batch(32)\n",
        "c = c.batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNr11MQYHKLx"
      },
      "outputs": [],
      "source": [
        "validation_combined_dataset = tf.data.Dataset.zip(((val_a,val_b),val_c))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDhu62UzGjcb"
      },
      "outputs": [],
      "source": [
        "img_features = []\n",
        "for img_batch, img_label_batch in validation_dataset:\n",
        "    for singe in img_batch:\n",
        "        img_features.append(singe)\n",
        "text_features = []\n",
        "text_labels = []\n",
        "for text_batch, label_batch in val_ds:\n",
        "    for single in text_batch:\n",
        "        text_features.append(single)\n",
        "    for single in label_batch:\n",
        "        text_labels.append(single)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4yqiifBiphs"
      },
      "source": [
        "# NICE TRY"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "wsEGBXwnnxX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d07vesyuiphs"
      },
      "outputs": [],
      "source": [
        "#get images\n",
        "img_features = []\n",
        "for img_batch, img_label_batch in train_dataset:\n",
        "    for singe in img_batch:\n",
        "        img_features.append(singe)\n",
        "\n",
        "\n",
        "#get text with images\n",
        "text_features = []\n",
        "text_labels = []\n",
        "for text_batch, label_batch in raw_train_ds:\n",
        "    for single in text_batch:\n",
        "        text_features.append(single)\n",
        "    for single in label_batch:\n",
        "        text_labels.append(single)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5yyTNpvipht"
      },
      "outputs": [],
      "source": [
        "img_features_st = tf.stack(img_features)\n",
        "text_features_st = tf.stack(text_features)\n",
        "labels_st = tf.stack(text_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UADaLCBPipht"
      },
      "outputs": [],
      "source": [
        "img_features_st_np = np.array(img_features_st)\n",
        "text_features_st_np = np.array(text_features_st)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbYf4zdIipht"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "har-d0Zuipht"
      },
      "outputs": [],
      "source": [
        "#PREPROC TEXT\n",
        "text_df = pd.DataFrame()\n",
        "text_df['text'] = text_features_st_np\n",
        "\n",
        "text_df['text'] = [x.decode(\"latin-1\") for x in text_df['text'].tolist()]\n",
        "\n",
        "\n",
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 8250\n",
        "trunc_type='post'\n",
        "oov_tok = '<OOV>'\n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "testing_sentences = []\n",
        "testing_labels = []\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "\n",
        "tokenizer.fit_on_texts(text_df['text'])\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(text_df['text'])\n",
        "\n",
        "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZcv3PO0ipht"
      },
      "outputs": [],
      "source": [
        "img_features_st_np.shape\n",
        "padded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIWO2FKSipht"
      },
      "outputs": [],
      "source": [
        "labels_st_np = np.array(labels_st)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lemFBHDGipht"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(labels_st_np)\n",
        "print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded)\n",
        "# invert first example\n",
        "inverted = label_encoder.inverse_transform([np.argmax(onehot_encoded[1, :])])\n",
        "\n",
        "onehot_encoded.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JHdveBoiphu"
      },
      "outputs": [],
      "source": [
        "a = tf.data.Dataset.from_tensor_slices(img_features_st_np)\n",
        "b = tf.data.Dataset.from_tensor_slices(padded)\n",
        "c = tf.data.Dataset.from_tensor_slices(onehot_encoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjJWmeTJiphu"
      },
      "outputs": [],
      "source": [
        "\n",
        "a = a.batch(32)\n",
        "b = b.batch(32)\n",
        "c = c.batch(32)\n",
        "combined_dataset = tf.data.Dataset.zip(((a,b),c))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR5Vqy2Ziphu"
      },
      "source": [
        "# make validation data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kqdWJIpiphu"
      },
      "outputs": [],
      "source": [
        "#get images\n",
        "img_features = []\n",
        "for img_batch, img_label_batch in validation_dataset:\n",
        "    for singe in img_batch:\n",
        "        img_features.append(singe)\n",
        "\n",
        "\n",
        "#get text with images\n",
        "text_features = []\n",
        "text_labels = []\n",
        "for text_batch, label_batch in raw_val_ds:\n",
        "    for single in text_batch:\n",
        "        text_features.append(single)\n",
        "    for single in label_batch:\n",
        "        text_labels.append(single)\n",
        "\n",
        "\n",
        "img_features_st = tf.stack(img_features)\n",
        "text_features_st = tf.stack(text_features)\n",
        "labels_st = tf.stack(text_labels)\n",
        "\n",
        "img_features_st_np = np.array(img_features_st)\n",
        "text_features_st_np = np.array(text_features_st)\n",
        "\n",
        "#PREPROC TEXT\n",
        "text_df = pd.DataFrame()\n",
        "text_df['text'] = text_features_st_np\n",
        "\n",
        "text_df['text'] = [x.decode(\"latin-1\") for x in text_df['text'].tolist()]\n",
        "\n",
        "\n",
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 8250\n",
        "trunc_type='post'\n",
        "oov_tok = '<OOV>'\n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "testing_sentences = []\n",
        "testing_labels = []\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "\n",
        "tokenizer.fit_on_texts(text_df['text'])\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(text_df['text'])\n",
        "\n",
        "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
        "\n",
        "\n",
        "labels_st_np = np.array(labels_st)\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(labels_st_np)\n",
        "print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded)\n",
        "# invert first example\n",
        "inverted = label_encoder.inverse_transform([np.argmax(onehot_encoded[1, :])])\n",
        "\n",
        "onehot_encoded.shape\n",
        "\n",
        "\n",
        "a_val = tf.data.Dataset.from_tensor_slices(img_features_st_np)\n",
        "b_val = tf.data.Dataset.from_tensor_slices(padded)\n",
        "c_val = tf.data.Dataset.from_tensor_slices(onehot_encoded)\n",
        "\n",
        "\n",
        "a_val = a_val.batch(32)\n",
        "b_val = b_val.batch(32)\n",
        "c_val = c_val.batch(32)\n",
        "combined_dataset_val = tf.data.Dataset.zip(((a_val,b_val),c_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, concatenate\n",
        "import tensorflow.keras.losses as losses"
      ],
      "metadata": {
        "id": "TLCc3LnztgcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ZRU0325Biphu"
      },
      "outputs": [],
      "source": [
        "try: \n",
        "    del model\n",
        "except:\n",
        "    2+2\n",
        "\n",
        "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs_img = tf.keras.layers.Dense(100)(x)\n",
        "#outputs_img = prediction_layer(x)\n",
        "\n",
        "text_input = tf.keras.layers.Input(shape=(8250,), name='text')\n",
        "# text_input = tf.keras.layers.Input(shape=(),)\n",
        "# text_input = layers.Embedding(input_dim=max_features+1, output_dim=embedding_dim, input_length=sequence_length, name='vectorized_text')\n",
        "\n",
        "net = tf.keras.layers.Embedding(vocab_size, 24)(text_input)\n",
        "net = tf.keras.layers.Conv1D(128, 5, activation='relu')(net)\n",
        "net = tf.keras.layers.GlobalAveragePooling1D()(net)\n",
        "net = tf.keras.layers.Dense(64, activation='relu')(net)\n",
        "net = tf.keras.layers.Dense(100)(net)\n",
        "net = tf.keras.layers.Dropout(0.2)(net)\n",
        "\n",
        "\n",
        "model_merging = concatenate([outputs_img,net]) \n",
        "\n",
        "final = tf.keras.layers.Dense(24, activation='sigmoid', name='finalmente')(model_merging)\n",
        "\n",
        "\n",
        "model = tf.keras.Model([inputs,text_input], final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI3BfyQiiphu"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "4qCkNmOPiphu"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.losses as losses\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "# model.compile(\n",
        "model.compile(\n",
        "    # loss=losses.BinaryCrossentropy(from_logits=True),\n",
        "    loss='categorical_crossentropy',\n",
        "    #optimizer='adam',\n",
        "    optimizer='adam', \n",
        "    # metrics=tf.metrics.BinaryAccuracy(threshold=0.0)\n",
        "    #metrics=tf.metrics.CategoricalAccuracy()\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lfPaPQoiphv",
        "outputId": "ecab62e3-b0a9-4409-8612-97777c39fd9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "208/208 [==============================] - 35s 168ms/step - loss: 2.3391 - accuracy: 0.2050 - val_loss: 4.5837 - val_accuracy: 0.0567\n",
            "Epoch 2/15\n",
            "208/208 [==============================] - 34s 166ms/step - loss: 2.3270 - accuracy: 0.2105 - val_loss: 4.6934 - val_accuracy: 0.0585\n",
            "Epoch 3/15\n",
            "208/208 [==============================] - 34s 166ms/step - loss: 2.3063 - accuracy: 0.2162 - val_loss: 4.7733 - val_accuracy: 0.0542\n",
            "Epoch 4/15\n",
            "208/208 [==============================] - 35s 166ms/step - loss: 2.2920 - accuracy: 0.2165 - val_loss: 4.8131 - val_accuracy: 0.0591\n",
            "Epoch 5/15\n",
            "208/208 [==============================] - 36s 171ms/step - loss: 2.2751 - accuracy: 0.2228 - val_loss: 4.8519 - val_accuracy: 0.0615\n",
            "Epoch 6/15\n",
            "208/208 [==============================] - 34s 165ms/step - loss: 2.2570 - accuracy: 0.2335 - val_loss: 4.9383 - val_accuracy: 0.0579\n",
            "Epoch 7/15\n",
            "208/208 [==============================] - 34s 164ms/step - loss: 2.2477 - accuracy: 0.2337 - val_loss: 4.9658 - val_accuracy: 0.0561\n",
            "Epoch 8/15\n",
            "208/208 [==============================] - 34s 165ms/step - loss: 2.2331 - accuracy: 0.2445 - val_loss: 5.0033 - val_accuracy: 0.0567\n",
            "Epoch 9/15\n",
            "208/208 [==============================] - 34s 166ms/step - loss: 2.2226 - accuracy: 0.2487 - val_loss: 5.0612 - val_accuracy: 0.0500\n",
            "Epoch 10/15\n",
            "208/208 [==============================] - 36s 172ms/step - loss: 2.1973 - accuracy: 0.2549 - val_loss: 5.1570 - val_accuracy: 0.0530\n",
            "Epoch 11/15\n",
            "208/208 [==============================] - 34s 165ms/step - loss: 2.1721 - accuracy: 0.2656 - val_loss: 5.2329 - val_accuracy: 0.0524\n",
            "Epoch 12/15\n",
            "208/208 [==============================] - 34s 165ms/step - loss: 2.1467 - accuracy: 0.2633 - val_loss: 5.2708 - val_accuracy: 0.0518\n",
            "Epoch 13/15\n",
            "208/208 [==============================] - 34s 165ms/step - loss: 2.1200 - accuracy: 0.2754 - val_loss: 5.3158 - val_accuracy: 0.0482\n",
            "Epoch 14/15\n",
            "208/208 [==============================] - 34s 165ms/step - loss: 2.0924 - accuracy: 0.2840 - val_loss: 5.4412 - val_accuracy: 0.0488\n",
            "Epoch 15/15\n",
            "208/208 [==============================] - 34s 165ms/step - loss: 2.0640 - accuracy: 0.2953 - val_loss: 5.4965 - val_accuracy: 0.0476\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7913882690>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "model.fit(combined_dataset, epochs = 15, validation_data =  combined_dataset_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0NAu8Fwiphv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "1133a71a1ea1957f99d77aa8df79443a56054a58dc52f3dd16ce72fc1cce1cf3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}